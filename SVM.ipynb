{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: SVM\n",
    "\n",
    "In this assignment you will use SKlearn’s implementation of an SVM classifier (called SVC).\n",
    "First you will divide the data to training and test set.\n",
    "Then, you will try different kernels using 5-fold cross validation.\n",
    "You will select the best kernel according to the TPR and FPR (with α=1.5). In addition, you will plot the result of each kernel in a ROC graph. \n",
    "\n",
    "After selecting the best kernel, you will try different values for the parameter C (the slack regularization) in the same method as above.\n",
    "\n",
    "Lastly, you will compute the performance of the chosen optimal kernel on the test set.\n",
    "\n",
    "\n",
    "\n",
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This jupyter notebook contains all the step by step instructions needed for this exercise.\n",
    "2. Write vectorized code whenever possible.\n",
    "3. You are responsible for the correctness of your code and should add as many tests as you see fit. Tests will not be graded nor checked.\n",
    "4. Write your functions in the provided `hw5.py` python module only. All the logic you write is imported and used in this jupyter notebook.\n",
    "5. You are not allowed to add imports to `hw5.py`, even if you only used them for testing.\n",
    "6. Your code must run without errors. During the environment setup, you were given a specific version of `numpy` to install. Changes of the configuration we provided are at your own risk. Code that cannot run will also earn you the grade of 0.\n",
    "7. Write your own code. Cheating will not be tolerated. \n",
    "8. Submission includes the `hw5.py` file and this notebook. Answers to qualitative questions should be written in markdown cells (with $\\LaTeX$ support).\n",
    "9. You are allowed to include additional functions.\n",
    "10. Submission: zip containing only the completed jupyter notebook and the python file `hw5.py`. Do not include the data or any directories. Name the file `ID1_ID2.zip` and submit *only one copy* of the assignment.\n",
    "\n",
    "\n",
    "## In this exercise you will perform the following:\n",
    "\n",
    "1. Load the dataset and split it to train and test. Feature scaling and feature selection were done for you.\n",
    "2. Train SVM classifiers with different kernels and kernel parameters using k-fold cross validation (using only the training dataset)\n",
    "3. Plot results and choose the best configuration based on 2 different metrics - accuracy and score (as defined below)\n",
    "4. Use the kernel with the best score, and do another round of hyper-parameter optimization, this time for different C values.\n",
    "5. For the kernel with the best score, train on the entire train dataset, predict on the test dataset and present the results on the test dataset.\n",
    "\n",
    "## important notes:\n",
    "1. You will only be graded for the code in `hw5.py`\n",
    "2. Each function you write will be tested automatically with python unit tests. you are not allowed to change the input or output formats of the functions.\n",
    "3. In order to avoid variable type mistakes and make sure your format is correct, several tests were added for you within this notebook. In this exercise we use python's `assert` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# make matplotlib figures appear inline in the notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.svm import SVC\n",
    "from numpy import count_nonzero, logical_and, logical_or, concatenate, mean, array_split, poly1d, polyfit\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the notebook automatically reload external python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - prepare data\n",
    "\n",
    "We will work on a standard data set of breast cancer samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function `prepare_data` (10 points)\n",
    "Implement the function `prepare_data` that splits the data into train and test datasets.\n",
    "\n",
    "Retrun values of `prepare_data` should be numpy arrays.\n",
    "\n",
    "Notice that before splitting the data you are required to shuffle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODUCTION_MODE = True \n",
    "\n",
    "if PRODUCTION_MODE:\n",
    "    SAMPLES_COUNT = 350 \n",
    "    FOLDS_COUNT = 5 \n",
    "    TRAIN_RATIO = 0.7\n",
    "else:\n",
    "    SAMPLES_COUNT = 150 \n",
    "    FOLDS_COUNT = 3 \n",
    "    TRAIN_RATIO = 0.6\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# data scaling and feature selection\n",
    "selected_features = ['worst perimeter', 'worst area', 'worst smoothness',\n",
    "       'worst compactness', 'worst concavity']\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df[selected_features].head()\n",
    "data = np.array(df[selected_features])\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "scaled_data = scaler.transform(data)\n",
    "scaled_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, test_data, test_labels = prepare_data(cancer.data, cancer.target, train_ratio=TRAIN_RATIO, max_count=SAMPLES_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - choose best kernel\n",
    "\n",
    "For each kernel, build the SVM classifier on the training using 5-fold cross validation.\n",
    "Calculate & print to the console the TPR and FPR on the test set.\n",
    "Select the best kernel according to the best αTPR-FPR (with α=1.5).\n",
    "The possible types for the kernel are:\n",
    "Polynomial Kernel – with the following degrees {2,3,4}\n",
    "RBF Kernel – with the following gamma values {1/200,1/20  ,1/2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function `get_stats`  (10 points)\n",
    "\n",
    "The function recieves 2 arrays: `prediction` and `expected` and computes:\n",
    "- true positive rate (tpr)\n",
    "- false positive rate (fpr)\n",
    "- accuracy\n",
    "\n",
    "Notice - you are requested to compute these values on your own, without using pre-built functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple test for validation.\n",
    "# it is recommended to add more tests.\n",
    "\n",
    "prediction = np.array([1,1,1,0,0])\n",
    "labels = np.array([1,1,1,0,0])\n",
    "tpr, fpr, accuracy = get_stats(prediction, labels)\n",
    "\n",
    "assert tpr==1.0\n",
    "assert fpr==0.0\n",
    "assert accuracy==1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function `get_k_fold_stats` (20 points)\n",
    "\n",
    "This function recieves the following:\n",
    "\n",
    "`clf` - a pre-configured sklearn learner\n",
    "\n",
    "`folds_array` - a numpy array that contains K sub arrays of data\n",
    "\n",
    "`labels_array`- a numpy array that contains K sub arrays of labels\n",
    "\n",
    "The function computes K fold cross validation averages of `tpr`, `fpr` and `accuracy`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple test for validation.\n",
    "# it is recommended to add more tests.\n",
    "clf=SVC()\n",
    "\n",
    "# a 3-folds arrays based on a dataset with 3 features and 12 samples\n",
    "folds_array=[np.array([[1.846e+02, 2.019e+03, 1.622e-01],\n",
    "        [1.588e+02, 1.956e+03, 1.238e-01],\n",
    "        [1.525e+02, 1.709e+03, 1.444e-01],\n",
    "        [9.887e+01, 5.677e+02, 2.098e-01]]),\n",
    " np.array([[1.522e+02, 1.575e+03, 1.374e-01],\n",
    "        [1.034e+02, 7.416e+02, 1.791e-01],\n",
    "        [1.532e+02, 1.606e+03, 1.442e-01],\n",
    "        [1.106e+02, 8.970e+02, 1.654e-01]]),\n",
    " np.array([[1.062e+02, 7.393e+02, 1.703e-01],\n",
    "        [9.765e+01, 7.114e+02, 1.853e-01],\n",
    "        [1.238e+02, 1.150e+03, 1.181e-01],\n",
    "        [1.365e+02, 1.299e+03, 1.396e-01]])]\n",
    "\n",
    "# a 3-folds labels array based on the same dataset\n",
    "labels_array = [np.array([1,1,0,0]),\n",
    "                np.array([1,0,1,1]),\n",
    "                np.array([0,1,0,0])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mean_tpr, mean_fpr, mean_accuracy = get_k_fold_stats(folds_array, labels_array, clf)\n",
    "\n",
    "assert 0.0<=mean_tpr<=1.0 \n",
    "assert 0.0<=mean_fpr<=1.0 \n",
    "assert 0.0<=mean_accuracy<=1.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function `compare_svms` (25 points)\n",
    "\n",
    "This function generates a dataframe  that compares the performance of classifiers with different hyper-parameters on a given (shuffeled) dataset with k-fold cross validation.\n",
    "Each row in the resulting dataframe contains the given classifier and and its average `tpr`, `fpr` and `accuracy` using k-fold cross validation.\n",
    "\n",
    "you are allowed to assume that this function only handles sklearn `SVC` classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple test for validation.\n",
    "# it is recommended to add more tests.\n",
    "\n",
    "# a dataset with 3 features and 12 samples\n",
    "data_array=np.array([[1.846e+02, 2.019e+03, 1.622e-01],\n",
    "                    [1.588e+02, 1.956e+03, 1.238e-01],\n",
    "                    [1.525e+02, 1.709e+03, 1.444e-01],\n",
    "                    [9.887e+01, 5.677e+02, 2.098e-01],\n",
    "                    [1.522e+02, 1.575e+03, 1.374e-01],\n",
    "                    [1.034e+02, 7.416e+02, 1.791e-01],\n",
    "                    [1.532e+02, 1.606e+03, 1.442e-01],\n",
    "                    [1.106e+02, 8.970e+02, 1.654e-01],\n",
    "                    [1.062e+02, 7.393e+02, 1.703e-01],\n",
    "                    [9.765e+01, 7.114e+02, 1.853e-01],\n",
    "                    [1.238e+02, 1.150e+03, 1.181e-01],\n",
    "                    [1.365e+02, 1.299e+03, 1.396e-01]])\n",
    "\n",
    "# a 3-folds labels array based on the same dataset\n",
    "labels_array = np.array([1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0])\n",
    "\n",
    "\n",
    "res = compare_svms(data_array,\n",
    "                 labels_array,\n",
    "                 folds_count=2,\n",
    "                 kernels_list=('poly', 'poly'),\n",
    "                 kernel_params=({'degree': 1}, {'degree': 2}))\n",
    "\n",
    "assert np.allclose([0.5, 0.333], res.tpr.tolist(), atol=0.1)\n",
    "assert np.allclose([0.166667, 0.375], res.fpr.tolist(), atol=0.1)\n",
    "assert np.allclose([0.666667, 0.416667], res.accuracy.tolist(), atol=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - compute the different SVMs and choose the best kernel and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = compare_svms(train_data,\n",
    "                   train_labels,\n",
    "                   folds_count=FOLDS_COUNT) # run the compare svms function on the train dataset\n",
    "\n",
    "#adding the score column\n",
    "res['score'] = res.apply(lambda x: ALPHA*x.tpr-x.fpr, axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement `get_most_accurate_kernel` (5 points)\n",
    "\n",
    "This function should return the row number in the `res` dataframe with the highest *accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate_kernel_idx = get_most_accurate_kernel()\n",
    "print (\"the chosen kernel is : %s.\\n\\nkernel details: \\n%s\" % (accurate_kernel_idx, res.iloc[accurate_kernel_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement `get_kernel_with_highest_score` (5 points)\n",
    "\n",
    "This function should return the row number in the `res` dataframe with the highest *score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel_idx = get_kernel_with_highest_score()\n",
    "print (\"the chosen kernel is : %s.\\n\\nkernel details: \\n%s\" % (best_kernel_idx, res.iloc[best_kernel_idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement `plot_roc_curve_with_score` (10 points)\n",
    "\n",
    "This function receives the result dataframe and the alpha used to calculate the score.\n",
    "It should create a scatter plot of the ROC curve (TPR vs FPR) and add a straight line in the form :\n",
    "                                        $$y=\\alpha*x + b$$\n",
    "that passes through the best kernel in the graph (i.e., with the highest *score*)\n",
    "Note: this can be a different point than the point with highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_with_score(res, alpha_slope=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: choose the optimal C value for the chosen kernel \n",
    "\n",
    "For the kernel with the best *score*, examine C values that are all the combinations \n",
    "$$\\{{10^i*\\frac{j}{3}}\\}, \\quad \\textrm{where} \\quad i=\\{1,0,-1,-2,-3,-4\\} \\quad \\textrm{and} \\quad  j={ 3,2,1}  $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function `evaluate_c_param` (5 points)\n",
    "\n",
    "The function `evaluate_c_param` should use the function `compare_svms`, but this time evaluate the same kernel for different C values as described above.\n",
    "\n",
    "The return value should be similar to `compare_svms`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_c_param = evaluate_c_param(train_data,train_labels, FOLDS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_c_param['score'] = res_c_param.apply(lambda x: ALPHA*x.tpr-x.fpr, axis=1)\n",
    "\n",
    "res_c_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the ROC curve\n",
    "\n",
    "x=res_c_param.fpr.tolist()\n",
    "y=res_c_param.tpr.tolist()\n",
    "z = np.polyfit(x, y, 3)\n",
    "p = np.poly1d(z)\n",
    "xp = np.linspace(0, 1, 100)\n",
    "_ = plt.plot(x, y, '.', xp, p(xp), '-')\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: choose kernel and C value, and evaluate performance on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement function `get_test_set_performance`  (10 points)\n",
    "\n",
    "Train the chosen SVM on the entire train data. \n",
    "Then, predict on the test data and return the performance metrics of the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel_type, kernel_params, clf, tpr, fpr, accuracy = get_test_set_performance(train_data, train_labels, test_data, test_labels)\n",
    "\n",
    "print(\"the chose kernel is: %s. \\noptimal parameters: %s.\" % (kernel_type, kernel_params))\n",
    "print(\"test dataset: %s samples, %s positives, %s negatives\" % (len(test_labels),np.count_nonzero(test_labels==1), np.count_nonzero(test_labels==0)))\n",
    "print(\"performance on test set: tpr: %s, fpr: %s, accuracy: %s\" % (tpr, fpr, accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
